{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10861766,"sourceType":"datasetVersion","datasetId":6705158}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nHF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T12:11:27.400825Z","iopub.execute_input":"2025-03-10T12:11:27.401065Z","iopub.status.idle":"2025-03-10T12:11:27.692872Z","shell.execute_reply.started":"2025-03-10T12:11:27.401045Z","shell.execute_reply":"2025-03-10T12:11:27.691626Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Create PH-LLM Dataset for Sleep and fitness","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom huggingface_hub import create_repo, upload_file","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T12:11:27.694046Z","iopub.execute_input":"2025-03-10T12:11:27.694380Z","iopub.status.idle":"2025-03-10T12:11:28.311968Z","shell.execute_reply.started":"2025-03-10T12:11:27.694351Z","shell.execute_reply":"2025-03-10T12:11:28.310712Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Define repository details (ensure this repo name is for a dataset)\nrepo_id = \"johnjehiel/ph-llm-dataset\"  # replace with your Hugging Face username/repo name\n\n# Load the CSV dataset (assumed to have columns: 'Category', 'ID', 'Prompt', 'Response')\ncsv_path = \"/kaggle/input/sleep-and-fitness-dataset/PH-LLM Custom Dataset.csv\"\ndf = pd.read_csv(csv_path)\n\n# Stratified split by 'Category': 90% train, 10% test\ntrain_df, test_df = train_test_split(\n    df, test_size=0.1, stratify=df[\"Category\"], random_state=42\n)\n\n# Save the train and test splits as separate Parquet files\ntrain_parquet_path = \"ph-llm-dataset_train.parquet\"\ntest_parquet_path = \"ph-llm-dataset_test.parquet\"\ntrain_df.to_parquet(train_parquet_path, index=False)\ntest_df.to_parquet(test_parquet_path, index=False)\n\n# Create the dataset repository on Hugging Face (specify repo_type=\"dataset\")\ncreate_repo(repo_id=repo_id, token=HF_TOKEN, repo_type=\"dataset\", exist_ok=True)\n\n# Upload the train split to the dataset repository\nupload_file(\n    path_or_fileobj=train_parquet_path,\n    path_in_repo=\"ph-llm-dataset_train.parquet\",\n    repo_id=repo_id,\n    token=HF_TOKEN,\n    repo_type=\"dataset\",  # IMPORTANT: ensure you're uploading to a dataset repo\n    commit_message=\"Upload train split (90%) for sleep and fitness\"\n)\n\n# Upload the test split to the dataset repository\nupload_file(\n    path_or_fileobj=test_parquet_path,\n    path_in_repo=\"ph-llm-dataset_test.parquet\",\n    repo_id=repo_id,\n    token=HF_TOKEN,\n    repo_type=\"dataset\",  # IMPORTANT: ensure you're uploading to a dataset repo\n    commit_message=\"Upload test split (10%) for sleep and fitness\"\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T06:57:05.389238Z","iopub.execute_input":"2025-03-10T06:57:05.389658Z","iopub.status.idle":"2025-03-10T06:57:08.160021Z","shell.execute_reply.started":"2025-03-10T06:57:05.389626Z","shell.execute_reply":"2025-03-10T06:57:08.158714Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Login using e.g. `huggingface-cli login` to access this dataset\nds = load_dataset(\"johnjehiel/ph-llm-dataset\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T08:11:43.341491Z","iopub.execute_input":"2025-03-10T08:11:43.341864Z","iopub.status.idle":"2025-03-10T08:11:49.231220Z","shell.execute_reply.started":"2025-03-10T08:11:43.341833Z","shell.execute_reply":"2025-03-10T08:11:49.230285Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"ph-llm-dataset_train.parquet:   0%|          | 0.00/2.19M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44d2747cf4f145b5a7f73c8432ee9ee1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ph-llm-dataset_test.parquet:   0%|          | 0.00/252k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1bc90ad86c946b4be3dadf27250a3bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1557 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a91ab65166246b6aee0380d7a5ccee9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/173 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e960feb00453485682d5576fc25b0d19"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T08:11:49.232301Z","iopub.execute_input":"2025-03-10T08:11:49.232839Z","iopub.status.idle":"2025-03-10T08:11:49.238759Z","shell.execute_reply.started":"2025-03-10T08:11:49.232808Z","shell.execute_reply":"2025-03-10T08:11:49.237731Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 1557\n    })\n    test: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 173\n    })\n})"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# Create MMLU clinical knowledge dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset, DatasetDict, concatenate_datasets\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T12:11:28.313846Z","iopub.execute_input":"2025-03-10T12:11:28.314335Z","iopub.status.idle":"2025-03-10T12:11:28.318481Z","shell.execute_reply.started":"2025-03-10T12:11:28.314288Z","shell.execute_reply":"2025-03-10T12:11:28.317357Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Load the mmlu clinical knowledge dataset\nmmlu_ds = load_dataset(\"openlifescienceai/mmlu_clinical_knowledge\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T12:11:28.319552Z","iopub.execute_input":"2025-03-10T12:11:28.319834Z","iopub.status.idle":"2025-03-10T12:11:31.359423Z","shell.execute_reply.started":"2025-03-10T12:11:28.319815Z","shell.execute_reply":"2025-03-10T12:11:31.358462Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"prompt_template = \"\"\"You are a medical expert {specialization}. Answer the following question by selecting the correct option.\n\n### Question:\n{question}\n\n### Options:\n(A) {option_A}\n(B) {option_B}\n(C) {option_C}\n(D) {option_D}\n\"\"\"\nresponse_template = \"Answer: ({correct_option}) {correct_answer}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T12:32:39.701612Z","iopub.execute_input":"2025-03-10T12:32:39.701896Z","iopub.status.idle":"2025-03-10T12:32:39.706330Z","shell.execute_reply.started":"2025-03-10T12:32:39.701877Z","shell.execute_reply":"2025-03-10T12:32:39.705221Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def format_prompt_response(record):\n    # Extract data from the 'data' dictionary.\n    data = record[\"data\"]\n    question = data.get(\"Question\", \"\")\n    options = data.get(\"Options\", {})\n    option_A = options.get(\"A\", \"\")\n    option_B = options.get(\"B\", \"\")\n    option_C = options.get(\"C\", \"\")\n    option_D = options.get(\"D\", \"\")\n    specialization = \"specialized in \" + \" \".join(record[\"subject_name\"].split(\"_\")) if record[\"subject_name\"] else \"\"\n    prompt = prompt_template.format(\n        specialization=specialization,\n        question=question,\n        option_A=option_A,\n        option_B=option_B,\n        option_C=option_C,\n        option_D=option_D\n    )\n    correct_answer = data.get(\"Correct Answer\", \"\")\n    correct_option = data.get(\"Correct Option\", \"\")\n    response = response_template.format(\n        correct_option=correct_option,\n        correct_answer=correct_answer\n    )\n    return {\n        \"Category\": record[\"subject_name\"],\n        \"ID\": record[\"id\"],\n        \"Prompt\": prompt,\n        \"Response\": response\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T12:54:26.771553Z","iopub.execute_input":"2025-03-10T12:54:26.771871Z","iopub.status.idle":"2025-03-10T12:54:26.778377Z","shell.execute_reply.started":"2025-03-10T12:54:26.771843Z","shell.execute_reply":"2025-03-10T12:54:26.777009Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"# Convert the \"test\" split to prompt–response pairs\nconverted_test = mmlu_ds[\"test\"].map(format_prompt_response)\nconverted_test = converted_test.remove_columns(['subject_name', 'data', 'id'])\n# Convert the \"validation\" split\nconverted_validation = mmlu_ds[\"validation\"].map(format_prompt_response)\nconverted_validation = converted_validation.remove_columns(['subject_name', 'data', 'id'])\n# Create a new DatasetDict\nnew_data = DatasetDict({\n    \"train\": converted_test,  # will be added to the \"train\" split\n    \"test\": converted_validation  # will be added to the \"test\" split\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T12:32:51.144416Z","iopub.execute_input":"2025-03-10T12:32:51.144745Z","iopub.status.idle":"2025-03-10T12:32:51.185227Z","shell.execute_reply.started":"2025-03-10T12:32:51.144725Z","shell.execute_reply":"2025-03-10T12:32:51.184093Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/29 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffbe9e6cd0bf4be099083c0692f02bcf"}},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"def add_sequential_ids(record, idx):\n    record['ID'] = idx+1\n    return record\n\n# Apply the function to both splits\nnew_data[\"train\"] = new_data[\"train\"].map(add_sequential_ids, with_indices=True)\nnew_data[\"test\"] = new_data[\"test\"].map(add_sequential_ids, with_indices=True)\n\nprint(new_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T12:36:32.905558Z","iopub.execute_input":"2025-03-10T12:36:32.905857Z","iopub.status.idle":"2025-03-10T12:36:32.964473Z","shell.execute_reply.started":"2025-03-10T12:36:32.905839Z","shell.execute_reply":"2025-03-10T12:36:32.963391Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/265 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"764f1d45563c4ca89a88bf05401b9cf4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/29 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0661e7e033034f9d886a7bee79124d13"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 265\n    })\n    test: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 29\n    })\n})\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# Load the existing dataset from Hugging Face\nexisting_ds = load_dataset(\"johnjehiel/ph-llm-dataset\")\n\n# Append (concatenate) the new prompt–response pairs to the existing splits.\nupdated_train = concatenate_datasets([existing_ds[\"train\"], new_data[\"train\"]])\nupdated_test = concatenate_datasets([existing_ds[\"test\"], new_data[\"test\"]])\n\n# Create an updated DatasetDict\nupdated_ds = DatasetDict({\n    \"train\": updated_train,\n    \"test\": updated_test\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T12:41:04.850765Z","iopub.execute_input":"2025-03-10T12:41:04.851096Z","iopub.status.idle":"2025-03-10T12:41:09.409598Z","shell.execute_reply.started":"2025-03-10T12:41:04.851067Z","shell.execute_reply":"2025-03-10T12:41:09.408270Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"ph-llm-dataset_train.parquet:   0%|          | 0.00/2.19M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"877e38c2bdf946d48ff81ae787b6595d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ph-llm-dataset_test.parquet:   0%|          | 0.00/252k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"258deddf627e4c4f89a419b50066e451"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1557 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb4770d8f4fc4e97a3336859078e4a1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/173 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6781102dff741dd8c64ef9f46233b67"}},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"# Convert each split to a Parquet file (local temporary files)\ntrain_parquet_path = \"updated_train.parquet\"\ntest_parquet_path = \"updated_test.parquet\"\n\n# Save the splits to Parquet\nupdated_ds[\"train\"].to_parquet(train_parquet_path)\nupdated_ds[\"test\"].to_parquet(test_parquet_path)\n\nrepo_id = \"johnjehiel/ph-llm-dataset\"\ncreate_repo(repo_id=repo_id, token=HF_TOKEN, repo_type=\"dataset\", exist_ok=True)\n\n# Upload the updated train split using the existing file name in the repo\nupload_file(\n    path_or_fileobj=train_parquet_path,\n    path_in_repo=\"ph-llm-dataset_train.parquet\",  # using the existing train file name\n    repo_id=repo_id,\n    token=HF_TOKEN,\n    repo_type=\"dataset\", \n    commit_message=\"Update train split with mmlu clinical knowledge data\"\n)\n\n# Upload the updated test split using the existing file name in the repo\nupload_file(\n    path_or_fileobj=test_parquet_path,\n    path_in_repo=\"ph-llm-dataset_test.parquet\",  # using the existing test file name\n    repo_id=repo_id,\n    token=HF_TOKEN,\n    repo_type=\"dataset\",\n    commit_message=\"Update test split with mmlu clinical knowledge data\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T12:47:38.444661Z","iopub.execute_input":"2025-03-10T12:47:38.444991Z","iopub.status.idle":"2025-03-10T12:47:43.993872Z","shell.execute_reply.started":"2025-03-10T12:47:38.444964Z","shell.execute_reply":"2025-03-10T12:47:43.992427Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bda1a209d8674a49a7842e01f1abdb29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f4eb1e0eb4c485693ee5b13c85c76af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"updated_train.parquet:   0%|          | 0.00/2.23M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87b5106c9be4474793d596712de045f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"updated_test.parquet:   0%|          | 0.00/257k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebea5455f24b4083a301bbd2ee934e26"}},"metadata":{}},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/datasets/johnjehiel/ph-llm-dataset/commit/6551f0c3667130c7eef6989a97b55c9bc7941925', commit_message='Update test split with mmlu clinical knowledge data', commit_description='', oid='6551f0c3667130c7eef6989a97b55c9bc7941925', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/johnjehiel/ph-llm-dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='johnjehiel/ph-llm-dataset'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"ds = load_dataset(repo_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T12:48:07.832188Z","iopub.execute_input":"2025-03-10T12:48:07.832555Z","iopub.status.idle":"2025-03-10T12:48:13.074293Z","shell.execute_reply.started":"2025-03-10T12:48:07.832527Z","shell.execute_reply":"2025-03-10T12:48:13.072906Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"ph-llm-dataset_train.parquet:   0%|          | 0.00/2.23M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8017df1653094299a8ee568a926eede5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ph-llm-dataset_test.parquet:   0%|          | 0.00/257k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"baeeea9d4ca14ef8939701eff9456c0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7d7f667ee8a4ae2904f2e4f81b6ce2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53f23837c2ed4fff8ded084f123c2ac2"}},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T12:48:19.397770Z","iopub.execute_input":"2025-03-10T12:48:19.398092Z","iopub.status.idle":"2025-03-10T12:48:19.403191Z","shell.execute_reply.started":"2025-03-10T12:48:19.398065Z","shell.execute_reply":"2025-03-10T12:48:19.402443Z"}},"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 1822\n    })\n    test: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 202\n    })\n})"},"metadata":{}}],"execution_count":54},{"cell_type":"markdown","source":"# Create dataset for MMLU college medicine","metadata":{}},{"cell_type":"code","source":"ds = load_dataset(\"openlifescienceai/mmlu_college_medicine\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T12:54:32.495869Z","iopub.execute_input":"2025-03-10T12:54:32.496177Z","iopub.status.idle":"2025-03-10T12:54:39.089025Z","shell.execute_reply.started":"2025-03-10T12:54:32.496152Z","shell.execute_reply":"2025-03-10T12:54:39.087734Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/854 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60ab1c62b598490ba905e79272265e92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/63.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a98f6a4c14140818fe8090c17ed78f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/14.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c545f10e452423bacc5b6382f0a4d1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dev-00000-of-00001.parquet:   0%|          | 0.00/8.61k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30dad78c5a2e4343a23dff70c0f785f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/173 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb7de60e82514db7b560a74dcb5130a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/22 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ee419c8930d4700acf01c6605e9d416"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e376fcca63247af82633b859bfff19d"}},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"# Convert the \"test\" split to prompt–response pairs\nconverted_test = ds[\"test\"].map(format_prompt_response)\nconverted_test = converted_test.remove_columns(['subject_name', 'data', 'id'])\n# Convert the \"validation\" split\nconverted_validation = ds[\"validation\"].map(format_prompt_response)\nconverted_validation = converted_validation.remove_columns(['subject_name', 'data', 'id'])\n# Create a new DatasetDict\nnew_data = DatasetDict({\n    \"train\": converted_test,  # will be added to the \"train\" split\n    \"test\": converted_validation  # will be added to the \"test\" split\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T12:55:14.933352Z","iopub.execute_input":"2025-03-10T12:55:14.933667Z","iopub.status.idle":"2025-03-10T12:55:15.014772Z","shell.execute_reply.started":"2025-03-10T12:55:14.933648Z","shell.execute_reply":"2025-03-10T12:55:15.013569Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/173 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11b8394565e24a508373d4af5b420475"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/22 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31129d185e8845fa8708821df5a22369"}},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"def add_sequential_ids(record, idx):\n    record['ID'] = idx+1\n    return record\n\n# Apply the function to both splits\nnew_data[\"train\"] = new_data[\"train\"].map(add_sequential_ids, with_indices=True)\nnew_data[\"test\"] = new_data[\"test\"].map(add_sequential_ids, with_indices=True)\n\nprint(new_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T12:55:45.071765Z","iopub.execute_input":"2025-03-10T12:55:45.072111Z","iopub.status.idle":"2025-03-10T12:55:45.130222Z","shell.execute_reply.started":"2025-03-10T12:55:45.072081Z","shell.execute_reply":"2025-03-10T12:55:45.128766Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/173 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e9079a641ac4b9fb71a33e34852aff6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/22 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f25c792a4604822b2d92686626068a7"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 173\n    })\n    test: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 22\n    })\n})\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"# Load the existing dataset from Hugging Face\nexisting_ds = load_dataset(\"johnjehiel/ph-llm-dataset\")\n\n# Append (concatenate) the new prompt–response pairs to the existing splits.\nupdated_train = concatenate_datasets([existing_ds[\"train\"], new_data[\"train\"]])\nupdated_test = concatenate_datasets([existing_ds[\"test\"], new_data[\"test\"]])\n\n# Create an updated DatasetDict\nupdated_ds = DatasetDict({\n    \"train\": updated_train,\n    \"test\": updated_test\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T12:57:53.289464Z","iopub.execute_input":"2025-03-10T12:57:53.289768Z","iopub.status.idle":"2025-03-10T12:57:56.201758Z","shell.execute_reply.started":"2025-03-10T12:57:53.289741Z","shell.execute_reply":"2025-03-10T12:57:56.200907Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"# Convert each split to a Parquet file (local temporary files)\ntrain_parquet_path = \"updated_train.parquet\"\ntest_parquet_path = \"updated_test.parquet\"\n\n# Save the splits to Parquet\nupdated_ds[\"train\"].to_parquet(train_parquet_path)\nupdated_ds[\"test\"].to_parquet(test_parquet_path)\n\nrepo_id = \"johnjehiel/ph-llm-dataset\"\ncreate_repo(repo_id=repo_id, token=HF_TOKEN, repo_type=\"dataset\", exist_ok=True)\n\n# Upload the updated train split using the existing file name in the repo\nupload_file(\n    path_or_fileobj=train_parquet_path,\n    path_in_repo=\"ph-llm-dataset_train.parquet\",  # using the existing train file name\n    repo_id=repo_id,\n    token=HF_TOKEN,\n    repo_type=\"dataset\", \n    commit_message=\"Update train split with mmlu college medicine data\"\n)\n\n# Upload the updated test split using the existing file name in the repo\nupload_file(\n    path_or_fileobj=test_parquet_path,\n    path_in_repo=\"ph-llm-dataset_test.parquet\",  # using the existing test file name\n    repo_id=repo_id,\n    token=HF_TOKEN,\n    repo_type=\"dataset\",\n    commit_message=\"Update test split with mmlu college medicine data\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:00:01.119959Z","iopub.execute_input":"2025-03-10T13:00:01.120338Z","iopub.status.idle":"2025-03-10T13:00:06.499627Z","shell.execute_reply.started":"2025-03-10T13:00:01.120276Z","shell.execute_reply":"2025-03-10T13:00:06.498587Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20a46fab0a324c53b54fcf2ac62e46ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4af9fae092c44c8b5bfe420eeb9c4ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"updated_train.parquet:   0%|          | 0.00/2.28M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7141f6837d454621b8f7b2aa8c0a9c66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"updated_test.parquet:   0%|          | 0.00/263k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77272327f50c49b784a1d8b6744aad7f"}},"metadata":{}},{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/datasets/johnjehiel/ph-llm-dataset/commit/1db0db814251e686363d33aae201d846149f4839', commit_message='Update test split with mmlu college medicine data', commit_description='', oid='1db0db814251e686363d33aae201d846149f4839', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/johnjehiel/ph-llm-dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='johnjehiel/ph-llm-dataset'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":75},{"cell_type":"code","source":"ds = load_dataset(repo_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:00:22.407860Z","iopub.execute_input":"2025-03-10T13:00:22.408172Z","iopub.status.idle":"2025-03-10T13:00:27.786893Z","shell.execute_reply.started":"2025-03-10T13:00:22.408145Z","shell.execute_reply":"2025-03-10T13:00:27.785832Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"ph-llm-dataset_train.parquet:   0%|          | 0.00/2.28M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ce4ba396ec04e8d8c31c8a248d80520"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ph-llm-dataset_test.parquet:   0%|          | 0.00/263k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bca71a84e24464bba35f427f534ff11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"416b5c15720b49fdb82179720681fce2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d995463b06e14f8d96dbb6d74a7066ed"}},"metadata":{}}],"execution_count":76},{"cell_type":"code","source":"ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:01:13.770267Z","iopub.execute_input":"2025-03-10T13:01:13.770704Z","iopub.status.idle":"2025-03-10T13:01:13.776817Z","shell.execute_reply.started":"2025-03-10T13:01:13.770673Z","shell.execute_reply":"2025-03-10T13:01:13.775932Z"}},"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 1995\n    })\n    test: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 224\n    })\n})"},"metadata":{}}],"execution_count":81},{"cell_type":"markdown","source":"# Create dataset for college biology","metadata":{}},{"cell_type":"code","source":"ds = load_dataset(\"openlifescienceai/mmlu_college_biology\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:03:06.025350Z","iopub.execute_input":"2025-03-10T13:03:06.025793Z","iopub.status.idle":"2025-03-10T13:03:13.130725Z","shell.execute_reply.started":"2025-03-10T13:03:06.025759Z","shell.execute_reply":"2025-03-10T13:03:13.128283Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/853 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c146952e16714443b70549c6e7fb41fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/49.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72fbe78a18e04c0cb267cc4b0933e97d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/12.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca6b639cfe2b4637945815df75fed0c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dev-00000-of-00001.parquet:   0%|          | 0.00/7.33k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31e29e14e24b46c9a7c04870ee947e23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/144 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99252ec7354a492b972e07cefc817d66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecb320bbf41f4a19bf76e54d41c59c8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"684dd8ebea154f5c9f0d952ae051007d"}},"metadata":{}}],"execution_count":82},{"cell_type":"code","source":"# Convert the \"test\" split to prompt–response pairs\nconverted_test = ds[\"test\"].map(format_prompt_response)\nconverted_test = converted_test.remove_columns(['subject_name', 'data', 'id'])\n# Convert the \"validation\" split\nconverted_validation = ds[\"validation\"].map(format_prompt_response)\nconverted_validation = converted_validation.remove_columns(['subject_name', 'data', 'id'])\n# Create a new DatasetDict\nnew_data = DatasetDict({\n    \"train\": converted_test,  # will be added to the \"train\" split\n    \"test\": converted_validation  # will be added to the \"test\" split\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:03:29.990138Z","iopub.execute_input":"2025-03-10T13:03:29.990525Z","iopub.status.idle":"2025-03-10T13:03:30.080052Z","shell.execute_reply.started":"2025-03-10T13:03:29.990496Z","shell.execute_reply":"2025-03-10T13:03:30.079173Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/144 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b644c6d4a7849f79a0dc5cba490a12e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/16 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4000124d80ad45dc83cbff6911212848"}},"metadata":{}}],"execution_count":83},{"cell_type":"code","source":"def add_sequential_ids(record, idx):\n    record['ID'] = idx+1\n    return record\n\n# Apply the function to both splits\nnew_data[\"train\"] = new_data[\"train\"].map(add_sequential_ids, with_indices=True)\nnew_data[\"test\"] = new_data[\"test\"].map(add_sequential_ids, with_indices=True)\n\nprint(new_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:03:47.435950Z","iopub.execute_input":"2025-03-10T13:03:47.436327Z","iopub.status.idle":"2025-03-10T13:03:47.490227Z","shell.execute_reply.started":"2025-03-10T13:03:47.436276Z","shell.execute_reply":"2025-03-10T13:03:47.488587Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/144 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ebf3db3815c44ddb86f58cee696b706"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/16 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71b22dfff7584ca598630320e9009904"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 144\n    })\n    test: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 16\n    })\n})\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"# Load the existing dataset from Hugging Face\nexisting_ds = load_dataset(\"johnjehiel/ph-llm-dataset\")\n\n# Append (concatenate) the new prompt–response pairs to the existing splits.\nupdated_train = concatenate_datasets([existing_ds[\"train\"], new_data[\"train\"]])\nupdated_test = concatenate_datasets([existing_ds[\"test\"], new_data[\"test\"]])\n\n# Create an updated DatasetDict\nupdated_ds = DatasetDict({\n    \"train\": updated_train,\n    \"test\": updated_test\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:04:12.069271Z","iopub.execute_input":"2025-03-10T13:04:12.069648Z","iopub.status.idle":"2025-03-10T13:04:14.808124Z","shell.execute_reply.started":"2025-03-10T13:04:12.069617Z","shell.execute_reply":"2025-03-10T13:04:14.806958Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"# Convert each split to a Parquet file (local temporary files)\ntrain_parquet_path = \"updated_train.parquet\"\ntest_parquet_path = \"updated_test.parquet\"\n\n# Save the splits to Parquet\nupdated_ds[\"train\"].to_parquet(train_parquet_path)\nupdated_ds[\"test\"].to_parquet(test_parquet_path)\n\nrepo_id = \"johnjehiel/ph-llm-dataset\"\ncreate_repo(repo_id=repo_id, token=HF_TOKEN, repo_type=\"dataset\", exist_ok=True)\n\n# Upload the updated train split using the existing file name in the repo\nupload_file(\n    path_or_fileobj=train_parquet_path,\n    path_in_repo=\"ph-llm-dataset_train.parquet\",  # using the existing train file name\n    repo_id=repo_id,\n    token=HF_TOKEN,\n    repo_type=\"dataset\", \n    commit_message=\"Update train split with mmlu college biology data\"\n)\n\n# Upload the updated test split using the existing file name in the repo\nupload_file(\n    path_or_fileobj=test_parquet_path,\n    path_in_repo=\"ph-llm-dataset_test.parquet\",  # using the existing test file name\n    repo_id=repo_id,\n    token=HF_TOKEN,\n    repo_type=\"dataset\",\n    commit_message=\"Update test split with mmlu college biology data\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:06:21.559903Z","iopub.execute_input":"2025-03-10T13:06:21.560196Z","iopub.status.idle":"2025-03-10T13:06:28.409516Z","shell.execute_reply.started":"2025-03-10T13:06:21.560171Z","shell.execute_reply":"2025-03-10T13:06:28.408517Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"859e1370326d4c1dada3b1989e76f0fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be2c553914c54ae6a21224aa48104445"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"updated_train.parquet:   0%|          | 0.00/2.32M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de9af534aa844f16b9849451569f6cf4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"updated_test.parquet:   0%|          | 0.00/267k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39acfc5205bb484486b13cc3c18ab6fc"}},"metadata":{}},{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/datasets/johnjehiel/ph-llm-dataset/commit/65a0fbf0a3cfa3db6f75130e3f6fc045e8119c19', commit_message='Update test split with mmlu college biology data', commit_description='', oid='65a0fbf0a3cfa3db6f75130e3f6fc045e8119c19', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/johnjehiel/ph-llm-dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='johnjehiel/ph-llm-dataset'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":86},{"cell_type":"code","source":"ds = load_dataset(repo_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:07:46.908050Z","iopub.execute_input":"2025-03-10T13:07:46.908454Z","iopub.status.idle":"2025-03-10T13:07:52.623748Z","shell.execute_reply.started":"2025-03-10T13:07:46.908412Z","shell.execute_reply":"2025-03-10T13:07:52.622795Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"ph-llm-dataset_train.parquet:   0%|          | 0.00/2.32M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6adc47c5660740248d2240f4b54e881f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ph-llm-dataset_test.parquet:   0%|          | 0.00/267k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f41a0fa455994c919663955cc56a4c53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2139 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9379e757e464025b62b3cc61b6a20c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/240 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2f786b66e8049bcbcd0ebc16de08803"}},"metadata":{}}],"execution_count":87},{"cell_type":"code","source":"ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:07:52.624675Z","iopub.execute_input":"2025-03-10T13:07:52.624887Z","iopub.status.idle":"2025-03-10T13:07:52.629179Z","shell.execute_reply.started":"2025-03-10T13:07:52.624870Z","shell.execute_reply":"2025-03-10T13:07:52.628487Z"}},"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 2139\n    })\n    test: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 240\n    })\n})"},"metadata":{}}],"execution_count":88},{"cell_type":"markdown","source":"# Create dataset for MMLU anatomy","metadata":{}},{"cell_type":"code","source":"ds = load_dataset(\"openlifescienceai/mmlu_anatomy\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:08:51.000894Z","iopub.execute_input":"2025-03-10T13:08:51.001192Z","iopub.status.idle":"2025-03-10T13:08:57.712336Z","shell.execute_reply.started":"2025-03-10T13:08:51.001173Z","shell.execute_reply":"2025-03-10T13:08:57.711586Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/853 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05d986c682884095adc18447b475a629"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/36.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a1e33a41ad34320815a7ae6bafbac5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/9.35k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fca78bdc18334545abd132b6a3019b72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dev-00000-of-00001.parquet:   0%|          | 0.00/6.57k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e6e751ae9c546818d7eebb138a33fe3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/135 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dbd943bf5564eae812aa82a305b281d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/14 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3eece89108b64eb5ab8b169fc3c61898"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95e0e5ad1894460bb608898e909ea52f"}},"metadata":{}}],"execution_count":89},{"cell_type":"code","source":"# Convert the \"test\" split to prompt–response pairs\nconverted_test = ds[\"test\"].map(format_prompt_response)\nconverted_test = converted_test.remove_columns(['subject_name', 'data', 'id'])\n# Convert the \"validation\" split\nconverted_validation = ds[\"validation\"].map(format_prompt_response)\nconverted_validation = converted_validation.remove_columns(['subject_name', 'data', 'id'])\n# Create a new DatasetDict\nnew_data = DatasetDict({\n    \"train\": converted_test,  # will be added to the \"train\" split\n    \"test\": converted_validation  # will be added to the \"test\" split\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:10:33.569329Z","iopub.execute_input":"2025-03-10T13:10:33.569663Z","iopub.status.idle":"2025-03-10T13:10:33.632994Z","shell.execute_reply.started":"2025-03-10T13:10:33.569643Z","shell.execute_reply":"2025-03-10T13:10:33.631711Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/135 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c60b4e3c0894ec28528d7cce4b67d98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"299fa913a01d40a28de36a5d38fc1168"}},"metadata":{}}],"execution_count":90},{"cell_type":"code","source":"def add_sequential_ids(record, idx):\n    record['ID'] = idx+1\n    return record\n\n# Apply the function to both splits\nnew_data[\"train\"] = new_data[\"train\"].map(add_sequential_ids, with_indices=True)\nnew_data[\"test\"] = new_data[\"test\"].map(add_sequential_ids, with_indices=True)\n\nprint(new_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:10:42.785790Z","iopub.execute_input":"2025-03-10T13:10:42.786082Z","iopub.status.idle":"2025-03-10T13:10:42.838903Z","shell.execute_reply.started":"2025-03-10T13:10:42.786062Z","shell.execute_reply":"2025-03-10T13:10:42.837951Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/135 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"287caa55f0234ce99a559668cae26e08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97ba46ab00e041d49f40de41dba9ec01"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 135\n    })\n    test: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 14\n    })\n})\n","output_type":"stream"}],"execution_count":91},{"cell_type":"code","source":"# Load the existing dataset from Hugging Face\nexisting_ds = load_dataset(\"johnjehiel/ph-llm-dataset\")\n\n# Append (concatenate) the new prompt–response pairs to the existing splits.\nupdated_train = concatenate_datasets([existing_ds[\"train\"], new_data[\"train\"]])\nupdated_test = concatenate_datasets([existing_ds[\"test\"], new_data[\"test\"]])\n\n# Create an updated DatasetDict\nupdated_ds = DatasetDict({\n    \"train\": updated_train,\n    \"test\": updated_test\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:11:13.472878Z","iopub.execute_input":"2025-03-10T13:11:13.473225Z","iopub.status.idle":"2025-03-10T13:11:15.731136Z","shell.execute_reply.started":"2025-03-10T13:11:13.473196Z","shell.execute_reply":"2025-03-10T13:11:15.729584Z"}},"outputs":[],"execution_count":93},{"cell_type":"code","source":"# Convert each split to a Parquet file (local temporary files)\ntrain_parquet_path = \"updated_train.parquet\"\ntest_parquet_path = \"updated_test.parquet\"\n\n# Save the splits to Parquet\nupdated_ds[\"train\"].to_parquet(train_parquet_path)\nupdated_ds[\"test\"].to_parquet(test_parquet_path)\n\nrepo_id = \"johnjehiel/ph-llm-dataset\"\ncreate_repo(repo_id=repo_id, token=HF_TOKEN, repo_type=\"dataset\", exist_ok=True)\n\n# Upload the updated train split using the existing file name in the repo\nupload_file(\n    path_or_fileobj=train_parquet_path,\n    path_in_repo=\"ph-llm-dataset_train.parquet\",  # using the existing train file name\n    repo_id=repo_id,\n    token=HF_TOKEN,\n    repo_type=\"dataset\", \n    commit_message=\"Update train split with mmlu anatomy data\"\n)\n\n# Upload the updated test split using the existing file name in the repo\nupload_file(\n    path_or_fileobj=test_parquet_path,\n    path_in_repo=\"ph-llm-dataset_test.parquet\",  # using the existing test file name\n    repo_id=repo_id,\n    token=HF_TOKEN,\n    repo_type=\"dataset\",\n    commit_message=\"Update test split with mmlu anatomy data\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:12:29.203248Z","iopub.execute_input":"2025-03-10T13:12:29.203637Z","iopub.status.idle":"2025-03-10T13:12:34.925952Z","shell.execute_reply.started":"2025-03-10T13:12:29.203609Z","shell.execute_reply":"2025-03-10T13:12:34.925093Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34671e5935c541c68fbcbdd37a35b998"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12781a1873ef4af2b92a2ec597aca897"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"updated_train.parquet:   0%|          | 0.00/2.34M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53b4ab7deb8a45979e37c6937a58d29d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"updated_test.parquet:   0%|          | 0.00/269k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6a36f6e36ad44059cdaf9864d471ba5"}},"metadata":{}},{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/datasets/johnjehiel/ph-llm-dataset/commit/2e412c86b33daa76bdaa54d6b4c6bf1ae734c6d9', commit_message='Update test split with mmlu anatomy data', commit_description='', oid='2e412c86b33daa76bdaa54d6b4c6bf1ae734c6d9', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/johnjehiel/ph-llm-dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='johnjehiel/ph-llm-dataset'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":94},{"cell_type":"code","source":"ds = load_dataset(repo_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:12:41.578665Z","iopub.execute_input":"2025-03-10T13:12:41.578995Z","iopub.status.idle":"2025-03-10T13:12:46.555004Z","shell.execute_reply.started":"2025-03-10T13:12:41.578967Z","shell.execute_reply":"2025-03-10T13:12:46.553762Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"ph-llm-dataset_train.parquet:   0%|          | 0.00/2.34M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2bab669bc0e421191d5b9477e13fa2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ph-llm-dataset_test.parquet:   0%|          | 0.00/269k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"273bf9a98bfc4ad7b3590a19eaf647dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"230e4170cfba4233a7c9a05fb0a4ae06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1aafe1b1a9b4919b85b7c0969cca088"}},"metadata":{}}],"execution_count":95},{"cell_type":"code","source":"ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:12:46.556187Z","iopub.execute_input":"2025-03-10T13:12:46.556602Z","iopub.status.idle":"2025-03-10T13:12:46.563043Z","shell.execute_reply.started":"2025-03-10T13:12:46.556570Z","shell.execute_reply":"2025-03-10T13:12:46.561887Z"}},"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 2274\n    })\n    test: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 254\n    })\n})"},"metadata":{}}],"execution_count":96},{"cell_type":"markdown","source":"# Create dataset for MMLU professional medicine","metadata":{}},{"cell_type":"code","source":"ds = load_dataset(\"openlifescienceai/mmlu_professional_medicine\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:13:58.277455Z","iopub.execute_input":"2025-03-10T13:13:58.277764Z","iopub.status.idle":"2025-03-10T13:14:04.379193Z","shell.execute_reply.started":"2025-03-10T13:13:58.277738Z","shell.execute_reply":"2025-03-10T13:14:04.377866Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/857 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80611214f9014b518428b4f673e1b28c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/149k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"731209a820d74c00aecddd585bec435c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06289642fa9844609df4437cc8568a84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dev-00000-of-00001.parquet:   0%|          | 0.00/11.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5db7f56d2dda49c994aaf20b7605adaa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/272 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a5f224f4bca4cc09cd3e7da06e18327"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/31 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b4f3f581be74aed8d35afddb47a9d2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc04930b677c4c46be32b973c2f4243b"}},"metadata":{}}],"execution_count":97},{"cell_type":"code","source":"# Convert the \"test\" split to prompt–response pairs\nconverted_test = ds[\"test\"].map(format_prompt_response)\nconverted_test = converted_test.remove_columns(['subject_name', 'data', 'id'])\n# Convert the \"validation\" split\nconverted_validation = ds[\"validation\"].map(format_prompt_response)\nconverted_validation = converted_validation.remove_columns(['subject_name', 'data', 'id'])\n# Create a new DatasetDict\nnew_data = DatasetDict({\n    \"train\": converted_test,  # will be added to the \"train\" split\n    \"test\": converted_validation  # will be added to the \"test\" split\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:14:08.167009Z","iopub.execute_input":"2025-03-10T13:14:08.167385Z","iopub.status.idle":"2025-03-10T13:14:08.257190Z","shell.execute_reply.started":"2025-03-10T13:14:08.167350Z","shell.execute_reply":"2025-03-10T13:14:08.256340Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/272 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f999a952e7b4f91b263f3bc40053f65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/31 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e138d36fba514d39a870f88f752ea99e"}},"metadata":{}}],"execution_count":98},{"cell_type":"code","source":"def add_sequential_ids(record, idx):\n    record['ID'] = idx+1\n    return record\n\n# Apply the function to both splits\nnew_data[\"train\"] = new_data[\"train\"].map(add_sequential_ids, with_indices=True)\nnew_data[\"test\"] = new_data[\"test\"].map(add_sequential_ids, with_indices=True)\n\nprint(new_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:14:21.438917Z","iopub.execute_input":"2025-03-10T13:14:21.439214Z","iopub.status.idle":"2025-03-10T13:14:21.493644Z","shell.execute_reply.started":"2025-03-10T13:14:21.439194Z","shell.execute_reply":"2025-03-10T13:14:21.492083Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/272 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f66d104f0eb4011a802b3fee68c2dba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/31 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16dce6f7cad34033bb373c7a14a2be49"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 272\n    })\n    test: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 31\n    })\n})\n","output_type":"stream"}],"execution_count":99},{"cell_type":"code","source":"# Load the existing dataset from Hugging Face\nexisting_ds = load_dataset(\"johnjehiel/ph-llm-dataset\")\n\n# Append (concatenate) the new prompt–response pairs to the existing splits.\nupdated_train = concatenate_datasets([existing_ds[\"train\"], new_data[\"train\"]])\nupdated_test = concatenate_datasets([existing_ds[\"test\"], new_data[\"test\"]])\n\n# Create an updated DatasetDict\nupdated_ds = DatasetDict({\n    \"train\": updated_train,\n    \"test\": updated_test\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:14:28.385207Z","iopub.execute_input":"2025-03-10T13:14:28.385550Z","iopub.status.idle":"2025-03-10T13:14:30.708668Z","shell.execute_reply.started":"2025-03-10T13:14:28.385529Z","shell.execute_reply":"2025-03-10T13:14:30.707278Z"}},"outputs":[],"execution_count":100},{"cell_type":"code","source":"# Convert each split to a Parquet file (local temporary files)\ntrain_parquet_path = \"updated_train.parquet\"\ntest_parquet_path = \"updated_test.parquet\"\n\n# Save the splits to Parquet\nupdated_ds[\"train\"].to_parquet(train_parquet_path)\nupdated_ds[\"test\"].to_parquet(test_parquet_path)\n\nrepo_id = \"johnjehiel/ph-llm-dataset\"\ncreate_repo(repo_id=repo_id, token=HF_TOKEN, repo_type=\"dataset\", exist_ok=True)\n\n# Upload the updated train split using the existing file name in the repo\nupload_file(\n    path_or_fileobj=train_parquet_path,\n    path_in_repo=\"ph-llm-dataset_train.parquet\",  # using the existing train file name\n    repo_id=repo_id,\n    token=HF_TOKEN,\n    repo_type=\"dataset\", \n    commit_message=\"Update train split with mmlu professional medicine data\"\n)\n\n# Upload the updated test split using the existing file name in the repo\nupload_file(\n    path_or_fileobj=test_parquet_path,\n    path_in_repo=\"ph-llm-dataset_test.parquet\",  # using the existing test file name\n    repo_id=repo_id,\n    token=HF_TOKEN,\n    repo_type=\"dataset\",\n    commit_message=\"Update test split with mmlu professional medicine data\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:15:27.119341Z","iopub.execute_input":"2025-03-10T13:15:27.119708Z","iopub.status.idle":"2025-03-10T13:15:32.911612Z","shell.execute_reply.started":"2025-03-10T13:15:27.119654Z","shell.execute_reply":"2025-03-10T13:15:32.910223Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f911c50b5ae14c49b71d575e56efc96c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c7d26523ca04ae58ead0e88a107efa0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"updated_train.parquet:   0%|          | 0.00/2.47M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5afce86c7e148bd977a78a8906d04b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"updated_test.parquet:   0%|          | 0.00/284k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10a846b06c4c42cfb2096a942d85db7f"}},"metadata":{}},{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/datasets/johnjehiel/ph-llm-dataset/commit/69e070424ede53ada0e9f23e8930b806bfe3c322', commit_message='Update test split with mmlu professional medicine data', commit_description='', oid='69e070424ede53ada0e9f23e8930b806bfe3c322', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/johnjehiel/ph-llm-dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='johnjehiel/ph-llm-dataset'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":101},{"cell_type":"code","source":"ds = load_dataset(repo_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:15:52.644148Z","iopub.execute_input":"2025-03-10T13:15:52.644496Z","iopub.status.idle":"2025-03-10T13:15:57.610019Z","shell.execute_reply.started":"2025-03-10T13:15:52.644468Z","shell.execute_reply":"2025-03-10T13:15:57.608690Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"ph-llm-dataset_train.parquet:   0%|          | 0.00/2.47M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a439ba4af9c4245900ac7ff81f1d70f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ph-llm-dataset_test.parquet:   0%|          | 0.00/284k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5aca1db90635413a9625cb10a0eaeade"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2546 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6d74c452bae46deaa0d14a906b20d8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/285 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6cb3c0d55cb484387e7bc1a58471353"}},"metadata":{}}],"execution_count":102},{"cell_type":"code","source":"ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:16:38.111862Z","iopub.execute_input":"2025-03-10T13:16:38.112217Z","iopub.status.idle":"2025-03-10T13:16:38.117797Z","shell.execute_reply.started":"2025-03-10T13:16:38.112187Z","shell.execute_reply":"2025-03-10T13:16:38.116849Z"}},"outputs":[{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 2546\n    })\n    test: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 285\n    })\n})"},"metadata":{}}],"execution_count":107},{"cell_type":"markdown","source":"# Create dataset for MMLU medical genetics","metadata":{}},{"cell_type":"code","source":"ds = load_dataset(\"openlifescienceai/mmlu_medical_genetics\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:17:16.919440Z","iopub.execute_input":"2025-03-10T13:17:16.919757Z","iopub.status.idle":"2025-03-10T13:17:24.610700Z","shell.execute_reply.started":"2025-03-10T13:17:16.919730Z","shell.execute_reply":"2025-03-10T13:17:24.609883Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/853 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42771d8db41343188e96ccf138b6fbc9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/27.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c919b9d78be4082a7112a4558008c1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/9.74k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2812c90790d749c3b5d2906018e6fab4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dev-00000-of-00001.parquet:   0%|          | 0.00/6.64k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27b211d515c84a858daf34a69f138878"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5a0da363668410e8ac51e9f085bc714"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/11 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69e0b63f00c8419dbd78389d2eb56196"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c33096d6964442394efa8d07ed79730"}},"metadata":{}}],"execution_count":108},{"cell_type":"code","source":"# Convert the \"test\" split to prompt–response pairs\nconverted_test = ds[\"test\"].map(format_prompt_response)\nconverted_test = converted_test.remove_columns(['subject_name', 'data', 'id'])\n# Convert the \"validation\" split\nconverted_validation = ds[\"validation\"].map(format_prompt_response)\nconverted_validation = converted_validation.remove_columns(['subject_name', 'data', 'id'])\n# Create a new DatasetDict\nnew_data = DatasetDict({\n    \"train\": converted_test,  # will be added to the \"train\" split\n    \"test\": converted_validation  # will be added to the \"test\" split\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:17:26.866828Z","iopub.execute_input":"2025-03-10T13:17:26.867122Z","iopub.status.idle":"2025-03-10T13:17:26.930965Z","shell.execute_reply.started":"2025-03-10T13:17:26.867102Z","shell.execute_reply":"2025-03-10T13:17:26.929747Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0277b0d1ceb4bdab4fc7e5f27f9b5aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/11 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21b5b795e08f496bb8bef12c857e5dd1"}},"metadata":{}}],"execution_count":109},{"cell_type":"code","source":"def add_sequential_ids(record, idx):\n    record['ID'] = idx+1\n    return record\n\n# Apply the function to both splits\nnew_data[\"train\"] = new_data[\"train\"].map(add_sequential_ids, with_indices=True)\nnew_data[\"test\"] = new_data[\"test\"].map(add_sequential_ids, with_indices=True)\n\nprint(new_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:17:41.488499Z","iopub.execute_input":"2025-03-10T13:17:41.488804Z","iopub.status.idle":"2025-03-10T13:17:41.542385Z","shell.execute_reply.started":"2025-03-10T13:17:41.488784Z","shell.execute_reply":"2025-03-10T13:17:41.540748Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a10eebfc83024d2b8a686bc6a6977230"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/11 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"740258ffc2b44857ad0aa3cf1977109d"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 100\n    })\n    test: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 11\n    })\n})\n","output_type":"stream"}],"execution_count":110},{"cell_type":"code","source":"# Load the existing dataset from Hugging Face\nexisting_ds = load_dataset(\"johnjehiel/ph-llm-dataset\")\n\n# Append (concatenate) the new prompt–response pairs to the existing splits.\nupdated_train = concatenate_datasets([existing_ds[\"train\"], new_data[\"train\"]])\nupdated_test = concatenate_datasets([existing_ds[\"test\"], new_data[\"test\"]])\n\n# Create an updated DatasetDict\nupdated_ds = DatasetDict({\n    \"train\": updated_train,\n    \"test\": updated_test\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:17:55.998507Z","iopub.execute_input":"2025-03-10T13:17:55.998871Z","iopub.status.idle":"2025-03-10T13:17:58.368169Z","shell.execute_reply.started":"2025-03-10T13:17:55.998841Z","shell.execute_reply":"2025-03-10T13:17:58.366993Z"}},"outputs":[],"execution_count":111},{"cell_type":"code","source":"# Convert each split to a Parquet file (local temporary files)\ntrain_parquet_path = \"updated_train.parquet\"\ntest_parquet_path = \"updated_test.parquet\"\n\n# Save the splits to Parquet\nupdated_ds[\"train\"].to_parquet(train_parquet_path)\nupdated_ds[\"test\"].to_parquet(test_parquet_path)\n\nrepo_id = \"johnjehiel/ph-llm-dataset\"\ncreate_repo(repo_id=repo_id, token=HF_TOKEN, repo_type=\"dataset\", exist_ok=True)\n\n# Upload the updated train split using the existing file name in the repo\nupload_file(\n    path_or_fileobj=train_parquet_path,\n    path_in_repo=\"ph-llm-dataset_train.parquet\",  # using the existing train file name\n    repo_id=repo_id,\n    token=HF_TOKEN,\n    repo_type=\"dataset\", \n    commit_message=\"Update train split with mmlu medical genetics data\"\n)\n\n# Upload the updated test split using the existing file name in the repo\nupload_file(\n    path_or_fileobj=test_parquet_path,\n    path_in_repo=\"ph-llm-dataset_test.parquet\",  # using the existing test file name\n    repo_id=repo_id,\n    token=HF_TOKEN,\n    repo_type=\"dataset\",\n    commit_message=\"Update test split with mmlu medical genetics data\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:18:48.314850Z","iopub.execute_input":"2025-03-10T13:18:48.315176Z","iopub.status.idle":"2025-03-10T13:18:54.066069Z","shell.execute_reply.started":"2025-03-10T13:18:48.315152Z","shell.execute_reply":"2025-03-10T13:18:54.064804Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a20863ce17c347a1ab4282388f4e9e9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d1ae1b629104696b543bcac1a0eb7ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"updated_train.parquet:   0%|          | 0.00/2.49M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"febecee73fec4c6b8f0319b81b088449"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"updated_test.parquet:   0%|          | 0.00/286k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb21df499af04174b30d3fba3a631169"}},"metadata":{}},{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/datasets/johnjehiel/ph-llm-dataset/commit/4813e37ca07225a1474a75ad8368b9e2db2af0b0', commit_message='Update test split with mmlu medical genetics data', commit_description='', oid='4813e37ca07225a1474a75ad8368b9e2db2af0b0', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/johnjehiel/ph-llm-dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='johnjehiel/ph-llm-dataset'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":112},{"cell_type":"code","source":"ds = load_dataset(repo_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:22:34.488552Z","iopub.execute_input":"2025-03-10T13:22:34.488905Z","iopub.status.idle":"2025-03-10T13:22:38.965333Z","shell.execute_reply.started":"2025-03-10T13:22:34.488876Z","shell.execute_reply":"2025-03-10T13:22:38.963912Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"ph-llm-dataset_train.parquet:   0%|          | 0.00/2.49M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a47dc883c7554cae9bcb07e8d53c29c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ph-llm-dataset_test.parquet:   0%|          | 0.00/286k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c40fdb7814de4044b1631798240c2cee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2646 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba0c61bb8a7f40f5ab889cc3232471ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/296 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26639f9ab7e744b8a55a88c349618326"}},"metadata":{}}],"execution_count":113},{"cell_type":"code","source":"ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:22:41.218461Z","iopub.execute_input":"2025-03-10T13:22:41.218844Z","iopub.status.idle":"2025-03-10T13:22:41.225318Z","shell.execute_reply.started":"2025-03-10T13:22:41.218816Z","shell.execute_reply":"2025-03-10T13:22:41.223705Z"}},"outputs":[{"execution_count":114,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 2646\n    })\n    test: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 296\n    })\n})"},"metadata":{}}],"execution_count":114},{"cell_type":"markdown","source":"# Create dataset for MedQA","metadata":{}},{"cell_type":"code","source":"ds = load_dataset(\"openlifescienceai/medqa\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:25:47.184686Z","iopub.execute_input":"2025-03-10T13:25:47.185022Z","iopub.status.idle":"2025-03-10T13:25:53.742462Z","shell.execute_reply.started":"2025-03-10T13:25:47.184995Z","shell.execute_reply":"2025-03-10T13:25:53.741571Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/858 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a0c077f4a1346e2a8b45d40405e2823"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/5.68M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89db41b3f1f14cce947b92a5a1893772"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/739k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49e37a872e6c4784a46c1db0294e4892"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dev-00000-of-00001.parquet:   0%|          | 0.00/720k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cad547040495465caf0818e4eeaa0022"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/10178 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cedb4362ca4843918ec49a3fff03b820"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1273 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d854497cf494e66b45de6ddc94f66c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/1272 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76cae0f00dc8411690d9a8b595572e30"}},"metadata":{}}],"execution_count":117},{"cell_type":"code","source":"# Convert the \"train\" split to prompt–response pairs\nconverted_test = ds[\"train\"].map(format_prompt_response)\nconverted_test = converted_test.remove_columns(['subject_name', 'data', 'id'])\n# Convert the \"test\" split\nconverted_validation = ds[\"test\"].map(format_prompt_response)\nconverted_validation = converted_validation.remove_columns(['subject_name', 'data', 'id'])\n# Create a new DatasetDict\nnew_data = DatasetDict({\n    \"train\": converted_test,  # will be added to the \"train\" split\n    \"test\": converted_validation  # will be added to the \"test\" split\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:27:29.290459Z","iopub.execute_input":"2025-03-10T13:27:29.290791Z","iopub.status.idle":"2025-03-10T13:27:30.499547Z","shell.execute_reply.started":"2025-03-10T13:27:29.290764Z","shell.execute_reply":"2025-03-10T13:27:30.498093Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10178 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6c1eaa57afd4d5195d09555df55b6f0"}},"metadata":{}}],"execution_count":119},{"cell_type":"code","source":"def add_sequential_ids(record, idx):\n    record['ID'] = idx+1\n    return record\n\n# Apply the function to both splits\nnew_data[\"train\"] = new_data[\"train\"].map(add_sequential_ids, with_indices=True)\nnew_data[\"test\"] = new_data[\"test\"].map(add_sequential_ids, with_indices=True)\n\nprint(new_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:27:40.230258Z","iopub.execute_input":"2025-03-10T13:27:40.230615Z","iopub.status.idle":"2025-03-10T13:27:40.742469Z","shell.execute_reply.started":"2025-03-10T13:27:40.230587Z","shell.execute_reply":"2025-03-10T13:27:40.741360Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10178 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29953f37ab984f3d9ef2295dd72b991e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1273 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"893731c620ac42eba551f5998d5862f4"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 10178\n    })\n    test: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 1273\n    })\n})\n","output_type":"stream"}],"execution_count":120},{"cell_type":"code","source":"new_data[\"train\"] = new_data[\"train\"].map(lambda x: {'Category': 'medqa'})\nnew_data[\"test\"] = new_data[\"test\"].map(lambda x: {'Category': 'medqa'})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:31:46.808650Z","iopub.execute_input":"2025-03-10T13:31:46.808969Z","iopub.status.idle":"2025-03-10T13:31:47.439488Z","shell.execute_reply.started":"2025-03-10T13:31:46.808948Z","shell.execute_reply":"2025-03-10T13:31:47.437953Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10178 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d275a7cdab504bcbabb236f837e501c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1273 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d51be097d79a4a3994f6730417fa4dab"}},"metadata":{}}],"execution_count":124},{"cell_type":"code","source":"# Load the existing dataset from Hugging Face\nexisting_ds = load_dataset(\"johnjehiel/ph-llm-dataset\")\n\n# Append (concatenate) the new prompt–response pairs to the existing splits.\nupdated_train = concatenate_datasets([existing_ds[\"train\"], new_data[\"train\"]])\nupdated_test = concatenate_datasets([existing_ds[\"test\"], new_data[\"test\"]])\n\n# Create an updated DatasetDict\nupdated_ds = DatasetDict({\n    \"train\": updated_train,\n    \"test\": updated_test\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:35:52.397219Z","iopub.execute_input":"2025-03-10T13:35:52.397649Z","iopub.status.idle":"2025-03-10T13:35:54.898264Z","shell.execute_reply.started":"2025-03-10T13:35:52.397606Z","shell.execute_reply":"2025-03-10T13:35:54.897083Z"}},"outputs":[],"execution_count":130},{"cell_type":"code","source":"# Convert each split to a Parquet file (local temporary files)\ntrain_parquet_path = \"updated_train.parquet\"\ntest_parquet_path = \"updated_test.parquet\"\n\n# Save the splits to Parquet\nupdated_ds[\"train\"].to_parquet(train_parquet_path)\nupdated_ds[\"test\"].to_parquet(test_parquet_path)\n\nrepo_id = \"johnjehiel/ph-llm-dataset\"\ncreate_repo(repo_id=repo_id, token=HF_TOKEN, repo_type=\"dataset\", exist_ok=True)\n\n# Upload the updated train split using the existing file name in the repo\nupload_file(\n    path_or_fileobj=train_parquet_path,\n    path_in_repo=\"ph-llm-dataset_train.parquet\",  # using the existing train file name\n    repo_id=repo_id,\n    token=HF_TOKEN,\n    repo_type=\"dataset\", \n    commit_message=\"Update train split with medqa data\"\n)\n\n# Upload the updated test split using the existing file name in the repo\nupload_file(\n    path_or_fileobj=test_parquet_path,\n    path_in_repo=\"ph-llm-dataset_test.parquet\",  # using the existing test file name\n    repo_id=repo_id,\n    token=HF_TOKEN,\n    repo_type=\"dataset\",\n    commit_message=\"Update test split with medqa data\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:37:20.927652Z","iopub.execute_input":"2025-03-10T13:37:20.927949Z","iopub.status.idle":"2025-03-10T13:37:26.764013Z","shell.execute_reply.started":"2025-03-10T13:37:20.927929Z","shell.execute_reply":"2025-03-10T13:37:26.763069Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/13 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c9cc3b2c6be4d91a4187ec8a85163ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6429ad705db4137bc1f74b94408d4c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"updated_train.parquet:   0%|          | 0.00/7.88M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f1dda3dc0a946e38a29d36f5da0d33b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"updated_test.parquet:   0%|          | 0.00/979k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a0ecaf9f8b64cc7af27fc8f7d0e903c"}},"metadata":{}},{"execution_count":131,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/datasets/johnjehiel/ph-llm-dataset/commit/5cb0b0a90d31ff73d5f730d14e3121750b908f5e', commit_message='Update test split with medqa data', commit_description='', oid='5cb0b0a90d31ff73d5f730d14e3121750b908f5e', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/johnjehiel/ph-llm-dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='johnjehiel/ph-llm-dataset'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":131},{"cell_type":"code","source":"ds = load_dataset(repo_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:37:30.905938Z","iopub.execute_input":"2025-03-10T13:37:30.906260Z","iopub.status.idle":"2025-03-10T13:37:35.900543Z","shell.execute_reply.started":"2025-03-10T13:37:30.906233Z","shell.execute_reply":"2025-03-10T13:37:35.899384Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"ph-llm-dataset_train.parquet:   0%|          | 0.00/7.88M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcb891f274f0455c9562c35a5b56cbaa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ph-llm-dataset_test.parquet:   0%|          | 0.00/979k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b82cdc05d0154ebb89fd30d6ca8e38a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13742b82a1814a5ab2f3f62108905732"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8869b7b6be9441988bb3ccf2d8b8aae5"}},"metadata":{}}],"execution_count":132},{"cell_type":"code","source":"ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:37:35.901887Z","iopub.execute_input":"2025-03-10T13:37:35.902157Z","iopub.status.idle":"2025-03-10T13:37:35.907145Z","shell.execute_reply.started":"2025-03-10T13:37:35.902133Z","shell.execute_reply":"2025-03-10T13:37:35.906052Z"}},"outputs":[{"execution_count":133,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 12824\n    })\n    test: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 1569\n    })\n})"},"metadata":{}}],"execution_count":133},{"cell_type":"markdown","source":"# Create dataset for PubMedQA","metadata":{}},{"cell_type":"code","source":"ds = load_dataset(\"openlifescienceai/pubmedqa\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:46:42.607660Z","iopub.execute_input":"2025-03-10T13:46:42.607945Z","iopub.status.idle":"2025-03-10T13:46:45.571415Z","shell.execute_reply.started":"2025-03-10T13:46:42.607927Z","shell.execute_reply":"2025-03-10T13:46:45.570260Z"}},"outputs":[],"execution_count":140},{"cell_type":"code","source":"ds[\"train\"] = concatenate_datasets([ds[\"train\"], ds[\"test\"]])\nds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:46:47.157776Z","iopub.execute_input":"2025-03-10T13:46:47.158095Z","iopub.status.idle":"2025-03-10T13:46:47.171053Z","shell.execute_reply.started":"2025-03-10T13:46:47.158067Z","shell.execute_reply":"2025-03-10T13:46:47.169751Z"}},"outputs":[{"execution_count":141,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'data'],\n        num_rows: 950\n    })\n    test: Dataset({\n        features: ['id', 'data'],\n        num_rows: 500\n    })\n    validation: Dataset({\n        features: ['id', 'data'],\n        num_rows: 50\n    })\n})"},"metadata":{}}],"execution_count":141},{"cell_type":"code","source":"prompt_template = \"\"\"You are a medical expert specialized in bio-medical research. Analyze the given context and answer the following question by selecting the correct or best option.\n\n### Context:\n{context}\n\n### Question:\n{question}\n\n### Options:\n(A) {option_A}\n(B) {option_B}\n(C) {option_C}\n\"\"\"\nresponse_template = \"\"\"Answer: ({correct_option}) {correct_answer}\nExplanation: {long_answer}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:58:40.314742Z","iopub.execute_input":"2025-03-10T13:58:40.315047Z","iopub.status.idle":"2025-03-10T13:58:40.319769Z","shell.execute_reply.started":"2025-03-10T13:58:40.315022Z","shell.execute_reply":"2025-03-10T13:58:40.318365Z"}},"outputs":[],"execution_count":143},{"cell_type":"code","source":"def format_prompt_response(record):\n    # Extract data from the 'data' dictionary.\n    data = record[\"data\"]\n    context = data.get(\"Context\", \"\")\n    question = data.get(\"Question\", \"\")\n    options = data.get(\"Options\", {})\n    option_A = options.get(\"A\", \"\")\n    option_B = options.get(\"B\", \"\")\n    option_C = options.get(\"C\", \"\")\n    prompt = prompt_template.format(\n        context=\"\\n\".join(context),\n        question=question,\n        option_A=option_A,\n        option_B=option_B,\n        option_C=option_C\n    )\n    correct_answer = data.get(\"Correct Answer\", \"\")\n    correct_option = data.get(\"Correct Option\", \"\")\n    long_answer = data.get(\"Long Answer\", \"\")\n    response = response_template.format(\n        correct_option=correct_option,\n        correct_answer=correct_answer,\n        long_answer=long_answer\n    )\n    return {\n        \"Category\": \"pubmedqa\",\n        \"ID\": record[\"id\"],\n        \"Prompt\": prompt,\n        \"Response\": response\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:59:09.893674Z","iopub.execute_input":"2025-03-10T13:59:09.893997Z","iopub.status.idle":"2025-03-10T13:59:09.899976Z","shell.execute_reply.started":"2025-03-10T13:59:09.893969Z","shell.execute_reply":"2025-03-10T13:59:09.898958Z"}},"outputs":[],"execution_count":144},{"cell_type":"code","source":"# Convert the \"train\" split to prompt–response pairs\nconverted_test = ds[\"train\"].map(format_prompt_response)\nconverted_test = converted_test.remove_columns(['data', 'id'])\n# Convert the \"validation\" split\nconverted_validation = ds[\"validation\"].map(format_prompt_response)\nconverted_validation = converted_validation.remove_columns(['data', 'id'])\n# Create a new DatasetDict\nnew_data = DatasetDict({\n    \"train\": converted_test,  # will be added to the \"train\" split\n    \"test\": converted_validation  # will be added to the \"test\" split\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T14:01:02.190953Z","iopub.execute_input":"2025-03-10T14:01:02.191232Z","iopub.status.idle":"2025-03-10T14:01:02.358424Z","shell.execute_reply.started":"2025-03-10T14:01:02.191209Z","shell.execute_reply":"2025-03-10T14:01:02.357095Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/950 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af90ba50fe564fbeb34ea18c7b61f4fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/50 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16b647ed8a0445d2bdd9b05e948db800"}},"metadata":{}}],"execution_count":146},{"cell_type":"code","source":"def add_sequential_ids(record, idx):\n    record['ID'] = idx+1\n    return record\n\n# Apply the function to both splits\nnew_data[\"train\"] = new_data[\"train\"].map(add_sequential_ids, with_indices=True)\nnew_data[\"test\"] = new_data[\"test\"].map(add_sequential_ids, with_indices=True)\n\nprint(new_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T14:01:30.009728Z","iopub.execute_input":"2025-03-10T14:01:30.010046Z","iopub.status.idle":"2025-03-10T14:01:30.097640Z","shell.execute_reply.started":"2025-03-10T14:01:30.010026Z","shell.execute_reply":"2025-03-10T14:01:30.096467Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/950 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f87b98b9c61b4daf9d6245b55a82bb7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/50 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"935768b8e015424191563b52575f32b4"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 950\n    })\n    test: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 50\n    })\n})\n","output_type":"stream"}],"execution_count":147},{"cell_type":"code","source":"# Load the existing dataset from Hugging Face\nexisting_ds = load_dataset(\"johnjehiel/ph-llm-dataset\")\n\n# Append (concatenate) the new prompt–response pairs to the existing splits.\nupdated_train = concatenate_datasets([existing_ds[\"train\"], new_data[\"train\"]])\nupdated_test = concatenate_datasets([existing_ds[\"test\"], new_data[\"test\"]])\n\n# Create an updated DatasetDict\nupdated_ds = DatasetDict({\n    \"train\": updated_train,\n    \"test\": updated_test\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T14:02:42.911046Z","iopub.execute_input":"2025-03-10T14:02:42.911429Z","iopub.status.idle":"2025-03-10T14:02:45.533272Z","shell.execute_reply.started":"2025-03-10T14:02:42.911409Z","shell.execute_reply":"2025-03-10T14:02:45.532111Z"}},"outputs":[],"execution_count":153},{"cell_type":"code","source":"# Convert each split to a Parquet file (local temporary files)\ntrain_parquet_path = \"updated_train.parquet\"\ntest_parquet_path = \"updated_test.parquet\"\n\n# Save the splits to Parquet\nupdated_ds[\"train\"].to_parquet(train_parquet_path)\nupdated_ds[\"test\"].to_parquet(test_parquet_path)\n\nrepo_id = \"johnjehiel/ph-llm-dataset\"\ncreate_repo(repo_id=repo_id, token=HF_TOKEN, repo_type=\"dataset\", exist_ok=True)\n\n# Upload the updated train split using the existing file name in the repo\nupload_file(\n    path_or_fileobj=train_parquet_path,\n    path_in_repo=\"ph-llm-dataset_train.parquet\",  # using the existing train file name\n    repo_id=repo_id,\n    token=HF_TOKEN,\n    repo_type=\"dataset\", \n    commit_message=\"Update train split with pubmedqa data\"\n)\n\n# Upload the updated test split using the existing file name in the repo\nupload_file(\n    path_or_fileobj=test_parquet_path,\n    path_in_repo=\"ph-llm-dataset_test.parquet\",  # using the existing test file name\n    repo_id=repo_id,\n    token=HF_TOKEN,\n    repo_type=\"dataset\",\n    commit_message=\"Update test split with pubmedqa data\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T14:03:30.413044Z","iopub.execute_input":"2025-03-10T14:03:30.413353Z","iopub.status.idle":"2025-03-10T14:03:36.409006Z","shell.execute_reply.started":"2025-03-10T14:03:30.413296Z","shell.execute_reply":"2025-03-10T14:03:36.407480Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/14 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95e9a024307b4fe2abd78dee9a1025eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b353bd8bcee4be387fc6f99ff57ae63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"updated_train.parquet:   0%|          | 0.00/8.83M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67d0700722394e5cbf0827e73ccbc94f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"updated_test.parquet:   0%|          | 0.00/1.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29ae4d5f3b0c428fa28e6e6f8225a6ae"}},"metadata":{}},{"execution_count":154,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/datasets/johnjehiel/ph-llm-dataset/commit/b75388cb7e69b011c9fae2730d3776d0a070cad8', commit_message='Update test split with pubmedqa data', commit_description='', oid='b75388cb7e69b011c9fae2730d3776d0a070cad8', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/johnjehiel/ph-llm-dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='johnjehiel/ph-llm-dataset'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":154},{"cell_type":"code","source":"ds = load_dataset(repo_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T14:03:45.674101Z","iopub.execute_input":"2025-03-10T14:03:45.674437Z","iopub.status.idle":"2025-03-10T14:03:50.506562Z","shell.execute_reply.started":"2025-03-10T14:03:45.674409Z","shell.execute_reply":"2025-03-10T14:03:50.505893Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"ph-llm-dataset_train.parquet:   0%|          | 0.00/8.83M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1456e8ea7ff45b897cd493051622e74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ph-llm-dataset_test.parquet:   0%|          | 0.00/1.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4b2ce2bc7a84b66bba90f67b1047658"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/13774 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"168ec0aa6bdb4c0ea016b0381b252263"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1619 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cff20c10a9a643daba12ce1ebe2759da"}},"metadata":{}}],"execution_count":155},{"cell_type":"code","source":"ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T14:03:50.513475Z","iopub.execute_input":"2025-03-10T14:03:50.513767Z","iopub.status.idle":"2025-03-10T14:03:50.519339Z","shell.execute_reply.started":"2025-03-10T14:03:50.513744Z","shell.execute_reply":"2025-03-10T14:03:50.518537Z"}},"outputs":[{"execution_count":156,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 13774\n    })\n    test: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 1619\n    })\n})"},"metadata":{}}],"execution_count":156},{"cell_type":"markdown","source":"# Create dataset for MedMCQA","metadata":{}},{"cell_type":"code","source":"ds = load_dataset(\"openlifescienceai/medmcqa\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:05:48.355698Z","iopub.execute_input":"2025-03-10T15:05:48.355980Z","iopub.status.idle":"2025-03-10T15:05:51.617081Z","shell.execute_reply.started":"2025-03-10T15:05:48.355960Z","shell.execute_reply":"2025-03-10T15:05:51.615398Z"}},"outputs":[],"execution_count":197},{"cell_type":"code","source":"keywords = [\n    'sleep', 'fitness', 'stress', 'heart', 'health', 'health care', 'personal', 'medical', 'cardio', 'medicine', 'exercise', 'smoking', 'smoker', 'alcohol', 'alcoholic', 'bmi', 'blood pressure', 'steps', 'step', 'run', 'jog', ' rem ', 'circadian', 'homeostatic', 'injury', ' train', 'etiology', 'etiological', 'recommend', 'advice', 'advise', 'assistance', 'assist', 'workout', 'work out', 'lifestyle', 'z-score', 'z score', 'athelete', 'athlete', 'sport', 'respiratory', 'fatigue', 'pressure', 'recover', 'hydrate', 'faint', 'drowsy', 'drowsiness', 'gym', 'muscle', 'sore', 'wake', 'rest', 'relax', 'insomnia', 'physic', 'care', 'calorie', 'fat loss', 'weight', 'height', 'mobility', 'activity', 'active'\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:05:58.074212Z","iopub.execute_input":"2025-03-10T15:05:58.074560Z","iopub.status.idle":"2025-03-10T15:05:58.079677Z","shell.execute_reply.started":"2025-03-10T15:05:58.074536Z","shell.execute_reply":"2025-03-10T15:05:58.078619Z"}},"outputs":[],"execution_count":199},{"cell_type":"code","source":"len(keywords)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:05:58.397824Z","iopub.execute_input":"2025-03-10T15:05:58.398127Z","iopub.status.idle":"2025-03-10T15:05:58.402569Z","shell.execute_reply.started":"2025-03-10T15:05:58.398106Z","shell.execute_reply":"2025-03-10T15:05:58.401769Z"}},"outputs":[{"execution_count":200,"output_type":"execute_result","data":{"text/plain":"65"},"metadata":{}}],"execution_count":200},{"cell_type":"code","source":"# Function to check if any keyword is present in a record\ndef contains_keyword(example):\n    for keyword in keywords:\n        if keyword in example['question'].lower():\n            return True\n    return False\n\n# Apply the filter to each split\nfor split in ds.keys():\n    ds[split] = ds[split].filter(contains_keyword)\n\nprint(ds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:06:02.193994Z","iopub.execute_input":"2025-03-10T15:06:02.194377Z","iopub.status.idle":"2025-03-10T15:06:06.989459Z","shell.execute_reply.started":"2025-03-10T15:06:02.194343Z","shell.execute_reply":"2025-03-10T15:06:06.988489Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/182822 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6802b063bd76422a8869c2a6b3226d1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/6150 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"076bda14a5554935b90013e516f98790"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/4183 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"496df80622034d3dbedd825058b0342a"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name'],\n        num_rows: 19180\n    })\n    test: Dataset({\n        features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name'],\n        num_rows: 501\n    })\n    validation: Dataset({\n        features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name'],\n        num_rows: 498\n    })\n})\n","output_type":"stream"}],"execution_count":201},{"cell_type":"code","source":"prompt_template = \"\"\"You are a medical expert specialized in {subject_name}. Answer the following question by selecting the correct or best option.\n\n### Question:\n{question}\n\n### Options:\n(A) {opa}\n(B) {opb}\n(C) {opc}\n(D) {opd}\n\"\"\"\nresponse_template = \"\"\"Answer: ({correct_option}) {correct_answer}\n{exp}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:06:17.861167Z","iopub.execute_input":"2025-03-10T15:06:17.861945Z","iopub.status.idle":"2025-03-10T15:06:17.866544Z","shell.execute_reply.started":"2025-03-10T15:06:17.861902Z","shell.execute_reply":"2025-03-10T15:06:17.865240Z"}},"outputs":[],"execution_count":202},{"cell_type":"code","source":"def format_prompt_response(record):\n    question = record[\"question\"]\n    opa = record[\"opa\"]\n    opb = record[\"opb\"]\n    opc = record[\"opc\"]\n    opd = record[\"opd\"]\n    subject_name = record['subject_name']\n    prompt = prompt_template.format(\n        subject_name=subject_name,\n        question=question,\n        opa=opa,\n        opb=opb,\n        opc=opc,\n        opd=opd\n    )\n    optionMap = {0:['A', opa], 1:['B', opb], 2:['C', opc], 3:['D', opd]}\n    correct_option = optionMap[record[\"cop\"]][0]\n    correct_answer = optionMap[record[\"cop\"]][1]\n    exp = \"\"\n    if record[\"exp\"]:\n        exp = f\"Explanation: {record['exp']}\" \n    response = response_template.format(\n        correct_option=correct_option,\n        correct_answer=correct_answer,\n        exp=exp\n    )\n    return {\n        \"Category\": \"MedMCQA\",\n        \"ID\": record[\"id\"],\n        \"Prompt\": prompt,\n        \"Response\": response\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:06:20.916903Z","iopub.execute_input":"2025-03-10T15:06:20.917178Z","iopub.status.idle":"2025-03-10T15:06:20.922535Z","shell.execute_reply.started":"2025-03-10T15:06:20.917159Z","shell.execute_reply":"2025-03-10T15:06:20.921663Z"}},"outputs":[],"execution_count":203},{"cell_type":"code","source":"# Convert the \"train\" split to prompt–response pairs\nconverted_train = ds[\"train\"].map(format_prompt_response)\nconverted_train = converted_train.remove_columns(['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name'])\n# Convert the \"validation\" split\nconverted_validation = ds[\"validation\"].map(format_prompt_response)\nconverted_validation = converted_validation.remove_columns(['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name'])\n# Create a new DatasetDict\nnew_data = DatasetDict({\n    \"train\": converted_train,  # will be added to the \"train\" split\n    \"test\": converted_validation  # will be added to the \"test\" split\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:06:38.647586Z","iopub.execute_input":"2025-03-10T15:06:38.647917Z","iopub.status.idle":"2025-03-10T15:06:42.249726Z","shell.execute_reply.started":"2025-03-10T15:06:38.647890Z","shell.execute_reply":"2025-03-10T15:06:42.249005Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/19180 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b42800b2bde14a268e5336b5828b2cfb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/498 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c33fe557a0534a7d8c5b87f2869f2447"}},"metadata":{}}],"execution_count":204},{"cell_type":"code","source":"def add_sequential_ids(record, idx):\n    record['ID'] = idx+1\n    return record\n\n# Apply the function to both splits\nnew_data[\"train\"] = new_data[\"train\"].map(add_sequential_ids, with_indices=True)\nnew_data[\"test\"] = new_data[\"test\"].map(add_sequential_ids, with_indices=True)\n\nprint(new_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:06:45.468796Z","iopub.execute_input":"2025-03-10T15:06:45.469102Z","iopub.status.idle":"2025-03-10T15:06:46.387494Z","shell.execute_reply.started":"2025-03-10T15:06:45.469078Z","shell.execute_reply":"2025-03-10T15:06:46.386145Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/19180 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57ec14bcbec041788c1bf0e6d5488bfb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/498 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05cde43e23fe4f90976c89dd972d96a4"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 19180\n    })\n    test: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 498\n    })\n})\n","output_type":"stream"}],"execution_count":205},{"cell_type":"code","source":"# Load the existing dataset from Hugging Face\nexisting_ds = load_dataset(\"johnjehiel/ph-llm-dataset\")\n\n# Append (concatenate) the new prompt–response pairs to the existing splits.\nupdated_train = concatenate_datasets([existing_ds[\"train\"], new_data[\"train\"]])\nupdated_test = concatenate_datasets([existing_ds[\"test\"], new_data[\"test\"]])\n\n# Create an updated DatasetDict\nupdated_ds = DatasetDict({\n    \"train\": updated_train,\n    \"test\": updated_test\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:09:09.095775Z","iopub.execute_input":"2025-03-10T15:09:09.096089Z","iopub.status.idle":"2025-03-10T15:09:11.504141Z","shell.execute_reply.started":"2025-03-10T15:09:09.096069Z","shell.execute_reply":"2025-03-10T15:09:11.503285Z"}},"outputs":[],"execution_count":214},{"cell_type":"code","source":"# Convert each split to a Parquet file (local temporary files)\ntrain_parquet_path = \"updated_train.parquet\"\ntest_parquet_path = \"updated_test.parquet\"\n\n# Save the splits to Parquet\nupdated_ds[\"train\"].to_parquet(train_parquet_path)\nupdated_ds[\"test\"].to_parquet(test_parquet_path)\n\nrepo_id = \"johnjehiel/ph-llm-dataset\"\ncreate_repo(repo_id=repo_id, token=HF_TOKEN, repo_type=\"dataset\", exist_ok=True)\n\n# Upload the updated train split using the existing file name in the repo\nupload_file(\n    path_or_fileobj=train_parquet_path,\n    path_in_repo=\"ph-llm-dataset_train.parquet\",  # using the existing train file name\n    repo_id=repo_id,\n    token=HF_TOKEN,\n    repo_type=\"dataset\", \n    commit_message=\"Update train split with medmcqa data\"\n)\n\n# Upload the updated test split using the existing file name in the repo\nupload_file(\n    path_or_fileobj=test_parquet_path,\n    path_in_repo=\"ph-llm-dataset_test.parquet\",  # using the existing test file name\n    repo_id=repo_id,\n    token=HF_TOKEN,\n    repo_type=\"dataset\",\n    commit_message=\"Update test split with medmcqa data\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:09:43.830547Z","iopub.execute_input":"2025-03-10T15:09:43.830872Z","iopub.status.idle":"2025-03-10T15:09:51.824830Z","shell.execute_reply.started":"2025-03-10T15:09:43.830844Z","shell.execute_reply":"2025-03-10T15:09:51.823070Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/33 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f27ce59e6dff4fe89a69536f883f4c5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dbd017aa4024a43b316a126a145872b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"updated_train.parquet:   0%|          | 0.00/19.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb76fb536f894ed4b45fcbbeefe4feeb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"updated_test.parquet:   0%|          | 0.00/1.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63459d7943e24481a957420533a951d2"}},"metadata":{}},{"execution_count":215,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/datasets/johnjehiel/ph-llm-dataset/commit/37cc676336376445e3ccb1f1a8717abbb0fff5b3', commit_message='Update test split with medmcqa data', commit_description='', oid='37cc676336376445e3ccb1f1a8717abbb0fff5b3', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/johnjehiel/ph-llm-dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='johnjehiel/ph-llm-dataset'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":215},{"cell_type":"code","source":"ds = load_dataset(repo_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:10:35.550076Z","iopub.execute_input":"2025-03-10T15:10:35.550446Z","iopub.status.idle":"2025-03-10T15:10:41.971653Z","shell.execute_reply.started":"2025-03-10T15:10:35.550416Z","shell.execute_reply":"2025-03-10T15:10:41.970535Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"ph-llm-dataset_train.parquet:   0%|          | 0.00/19.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d0050b179d54420b39da15c3352ef5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ph-llm-dataset_test.parquet:   0%|          | 0.00/1.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b772d7de5fba436e905e549f13f92ba6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec67f2920114413cbd7cee596329684c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98aeb5448e7d4fa8aa881cf6ce83003f"}},"metadata":{}}],"execution_count":216},{"cell_type":"code","source":"ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:10:44.298892Z","iopub.execute_input":"2025-03-10T15:10:44.299252Z","iopub.status.idle":"2025-03-10T15:10:44.305046Z","shell.execute_reply.started":"2025-03-10T15:10:44.299220Z","shell.execute_reply":"2025-03-10T15:10:44.303910Z"}},"outputs":[{"execution_count":217,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 32954\n    })\n    test: Dataset({\n        features: ['Category', 'ID', 'Prompt', 'Response'],\n        num_rows: 2117\n    })\n})"},"metadata":{}}],"execution_count":217},{"cell_type":"markdown","source":"# create dataset for Patient-Doctor interaction","metadata":{}},{"cell_type":"code","source":"ds = load_dataset(\"ruslanmv/ai-medical-chatbot\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:14:59.555835Z","iopub.execute_input":"2025-03-10T15:14:59.556105Z","iopub.status.idle":"2025-03-10T15:15:10.317939Z","shell.execute_reply.started":"2025-03-10T15:14:59.556087Z","shell.execute_reply":"2025-03-10T15:15:10.317227Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/863 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3c6f926991945de82dc18c9e0ee07a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dialogues.parquet:   0%|          | 0.00/142M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5e2526f4feb4668a3ca6cac5d9da0e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/256916 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcb3be9edc1f4cb9abe0199873266a8d"}},"metadata":{}}],"execution_count":218},{"cell_type":"code","source":"ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:15:10.318878Z","iopub.execute_input":"2025-03-10T15:15:10.319087Z","iopub.status.idle":"2025-03-10T15:15:10.324730Z","shell.execute_reply.started":"2025-03-10T15:15:10.319068Z","shell.execute_reply":"2025-03-10T15:15:10.323468Z"}},"outputs":[{"execution_count":219,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Description', 'Patient', 'Doctor'],\n        num_rows: 256916\n    })\n})"},"metadata":{}}],"execution_count":219},{"cell_type":"code","source":"ds[\"train\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T15:15:25.218435Z","iopub.execute_input":"2025-03-10T15:15:25.218765Z","iopub.status.idle":"2025-03-10T15:15:25.226078Z","shell.execute_reply.started":"2025-03-10T15:15:25.218737Z","shell.execute_reply":"2025-03-10T15:15:25.224204Z"}},"outputs":[{"execution_count":220,"output_type":"execute_result","data":{"text/plain":"{'Description': 'Q. What does abutment of the nerve root mean?',\n 'Patient': 'Hi doctor,I am just wondering what is abutting and abutment of the nerve root means in a back issue. Please explain. What treatment is required for\\xa0annular bulging and tear?',\n 'Doctor': 'Hi. I have gone through your query with diligence and would like you to know that I am here to help you. For further information consult a neurologist online -->'}"},"metadata":{}}],"execution_count":220},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}